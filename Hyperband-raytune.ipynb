{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9d42b9f-a136-46b6-b134-faefc49e19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from ray import tune\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e9a20e6-b7da-4464-8623-4bbaeaded050",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 2\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b29bb39d-8504-4129-80d3-4a88d61f845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/david/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1280, out_features=1000, bias=True)\n",
      "Linear(in_features=1280, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "print(model.classifier[1])\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "print(model.classifier[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16f08040-1cdd-4f0a-ae26-6ffa7ccd6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tirar essa parte, porque nÃ£o queremos testar redes diferentes\n",
    "\n",
    "# def define_model(trial):\n",
    "#     # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "#     n_layers = trial.suggest_int(\"n_layers\", 1, 3) # number of layers\n",
    "#     layers = []\n",
    "\n",
    "#     in_features = 1280\n",
    "#     for i in range(n_layers):\n",
    "#         out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128) # hidden units\n",
    "#         layers.append(nn.Linear(in_features, out_features))\n",
    "#         layers.append(nn.ReLU())\n",
    "#         p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5) # dropout ratio\n",
    "#         layers.append(nn.Dropout(p))\n",
    "\n",
    "#         in_features = out_features\n",
    "#     layers.append(nn.Linear(in_features, CLASSES))\n",
    "#     layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "#     return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c196c14f-de81-40bd-929f-5b49854b50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "img_size = 224\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.Resize((img_size,img_size)),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "668f505c-aba1-4e9f-8914-03f107078637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only horizontal flip augmentation.\n",
      "Using only horizontal flip augmentation.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from configs import Inputs\n",
    "from utils.augmentations import get_transforms\n",
    "from utils.data import FullRadiographSexDataset\n",
    "\n",
    "val_dataset = FullRadiographSexDataset(root_dir=Inputs.DATASET_DIR,\n",
    "                                       fold_nums=Inputs().val_folds,\n",
    "                                       transforms=get_transforms(Inputs(), subset=[\"train\"]))\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=2,\n",
    "                            shuffle=False,\n",
    "                            num_workers=0)\n",
    "\n",
    "train_dataset = FullRadiographSexDataset(root_dir=Inputs.DATASET_DIR,\n",
    "                                         fold_nums=Inputs().train_folds,\n",
    "                                         transforms=get_transforms(Inputs(), subset=[\"train\"]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5492dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
    "    \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"batch_size\": tune.choice([2, 4, 8, 16]),\n",
    "    \"optimizer_name\": tune.choice([\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "905c0d7c-d916-462f-9b15-c80035ac509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(config):\n",
    "\n",
    "    # Gerar o modelo\n",
    "    #model = define_model(trial).to(DEVICE)\n",
    "    model = torchvision.models.efficientnet_b0(weights=torchvision.models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # Gerar optimizer\n",
    "    optimizer_name = config['optimizer_name']\n",
    "    lr = config[\"lr\"]\n",
    "\n",
    "    print(optimizer_name, lr)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader, valid_loader = train_dataloader, val_dataloader\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoin_dir:\n",
    "            path = os.path.join(checkpoin_dir, \"checkpoint\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=loss, accuracy=accuracy)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f12e66a-ac69-4a0b-9da7-49d4b0d7f0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ray.tune.search.sample.Categorical object at 0x7f382538f640> <ray.tune.search.sample.Float object at 0x7f382538f310>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim' has no attribute '<ray.tune.search.sample.Categorical object at 0x7f382538f640>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m objective(config)\n",
      "Cell \u001b[0;32mIn[41], line 14\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     11\u001b[0m lr \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(optimizer_name, lr)\n\u001b[0;32m---> 14\u001b[0m optimizer \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(optim, optimizer_name)(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[1;32m     16\u001b[0m train_loader, valid_loader \u001b[39m=\u001b[39m train_dataloader, val_dataloader\n\u001b[1;32m     18\u001b[0m \u001b[39m# Training of the model.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.optim' has no attribute '<ray.tune.search.sample.Categorical object at 0x7f382538f640>'"
     ]
    }
   ],
   "source": [
    "objective(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5a9dd-cb6c-4ddd-9076-79b673c9e05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
