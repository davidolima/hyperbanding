{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dec5f9c-967b-42ee-a25c-11fcb5d31bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "model = torchvision.models.efficientnet_v2_m(pretrained=True)\n",
    "in_features = model.classifier[1]\n",
    "in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54409088-c58a-4980-b175-2d4af8fa2b2f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (0.12.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.1 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision) (1.21.2)\n",
      "Collecting torch==1.12.1\n",
      "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.3 MB 1.6 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torchvision) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision) (3.3)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0\n",
      "    Uninstalling torchvision-0.12.0:\n",
      "      Successfully uninstalled torchvision-0.12.0\n",
      "Successfully installed torch-1.12.1 torchvision-0.13.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e1b44b4-8a20-469b-aaaa-258f2727f251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd79f10-d59f-43eb-bbf9-e65b43f3219b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de794af8-58a4-44fb-91c5-e479514a5905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(1,31):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        for line in f: #ler cada linha do txt\n",
    "            fname = line.strip().split('/')[2] #retirar o \\n\n",
    "            sex = fname.split('-')[10]\n",
    "            age = fname.split('-')[-2][1:]\n",
    "            months = fname.split('-')[-1][1:3] #home/bernardo/datasets/pan-radiographs/1st-set\n",
    "\n",
    "            if fname.split('-')[0] == 'pan': #separar os arquivos pan e panreport\n",
    "                fpath = os.path.join(f'/home/bernardo/datasets/pan-radiographs/1st-set/images/{fname}')\n",
    "            else:\n",
    "                fpath = os.path.join(f'/home/bernardo/datasets/pan-radiographs/2nd-set/images/{fname}')\n",
    "            im = Image.open(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "680d2491-e055-461f-874a-c62d557a3006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STDV = [0.229, 0.224, 0.225]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "815e6472-8592-4c9c-bceb-8c72d19db8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.TrivialAugmentWide(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "class RadiographSexDataset_17000(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str,\n",
    "        fold_nums: list,\n",
    "        transforms = transform,\n",
    "        albumentations_package: bool=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.fold_nums = fold_nums\n",
    "        self.transforms = transforms\n",
    "        self.albumentations = albumentations_package\n",
    "        \n",
    "        train = [i for i in range(1, 20 + 1)]\n",
    "        val   = [i for i in range(21, 25 + 1)]\n",
    "        test  = [i for i in range(26, 30 + 1)]\n",
    "        \n",
    "        # labels\n",
    "        self.filepaths = []\n",
    "        for i in range(1,31):\n",
    "            filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "            with open(filepath) as f:\n",
    "                for line in f:\n",
    "                    fname = line.strip()\n",
    "                    self.filepaths.append(fname)\n",
    "                    \n",
    "        # this maybe useful later for reproducibility\n",
    "        self.filepaths.sort()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def _getitem_albumentations(self, filepath: str):\n",
    "        # Read image with OpenCV2 and convert it from BGR (OpenCV2) to RGB (most common format)\n",
    "        image = cv2.imread(filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # apply transformation with albumentations package\n",
    "        if self.transforms is not None:\n",
    "            img_tensor = self.transforms(image=image)[\"image\"]\n",
    "\n",
    "        return img_tensor\n",
    "\n",
    "    def _getitem_torchvision(self, filepath: str):\n",
    "        image = Image.open(filepath)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img_tensor = self.transforms(image)\n",
    "\n",
    "        return img_tensor\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # image and label\n",
    "        filepath = self.filepaths[index]\n",
    "        if fname.split('-')[0] == 'pan': \n",
    "            fpath = os.path.join(f'/home/bernardo/datasets/pan-radiographs/1st-set/images/{fname}')\n",
    "        else:\n",
    "            fpath = os.path.join(f'/home/bernardo/datasets/pan-radiographs/2nd-set/images/{fname}')\n",
    "\n",
    "        # get label\n",
    "        sex = fname.split('-')[10]\n",
    "        age = fname.split('-')[-2][1:]\n",
    "        months = fname.split('-')[-1][1:3]\n",
    "        \n",
    "        assert sex in ['F', 'M']\n",
    "        if sex == 'F':\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        label_tensor = torch.tensor(label, dtype=torch.int64)\n",
    "        img_tensor = Image.open(fpath)        \n",
    "        \n",
    "        return img_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86ee02c7-257e-4702-ba4a-d907bc6afe54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = RadiographSexDataset_17000(\n",
    "    root_dir=None,\n",
    "    fold_nums=30,\n",
    "    transforms=transform,\n",
    "    albumentations_package=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6b214a1-6244-4022-b4b5-a6ca3e9d317a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img, label in ds:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "513dece0-e532-434d-a572-a60083c719e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labels\n",
    "filepaths = []\n",
    "for i in range(1,31):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            fname = line.strip()\n",
    "            filepaths.append(fname)\n",
    "\n",
    "# for fold_num in range(self.fold_nums):\n",
    "#     if fname.split('-')[0] == 'pan': \n",
    "#         fpath = os.path.join(f'/home/bernardo/datasets/pan-radiographs/1st-set/images/{fname}')\n",
    "#     else:\n",
    "#         fpath = os.path.join(f'/home/bernardo/datasets/pan-radiographs/2nd-set/images/images/{fname}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4be837-0276-4379-9b95-65673280e1eb",
   "metadata": {},
   "source": [
    "## Contagem do nº de homens e mulheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be61ac42-1a61-45ae-a198-386c4565e2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males: 6341 Females: 10483\n"
     ]
    }
   ],
   "source": [
    "count_m = 0\n",
    "count_f = 0\n",
    "for i in range(1,30+1):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            img_relpath = line.strip()\n",
    "            filename = img_relpath.split('/')[-1]\n",
    "            sex = filename.split('-')[10]\n",
    "            #print(sex)\n",
    "            if sex == 'M':\n",
    "                count_m +=1\n",
    "            else:\n",
    "                count_f +=1\n",
    "\n",
    "print('Males:',count_m,'Females:',count_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2460ae3-e29c-4a91-a61a-0a7deef2b9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16824\n"
     ]
    }
   ],
   "source": [
    "count_1 = 0\n",
    "count_2 = 0\n",
    "for i in range(1,31):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        for line in f: #ler cada linha do txt\n",
    "            fname = line.strip().split('/')[2] #retirar o \\n\n",
    "            if fname.split('-')[0] == 'pan': #separar os arquivos pan e panreport\n",
    "                fpath = os.path.join(f'/home/bernardo/datasets/pan-radiographs/1st-set/images/{fname}')\n",
    "                count_1 +=1\n",
    "            else:\n",
    "                fpath = os.path.join(f'/home/bernardo/datasets/pan-radiographs/2nd-set/images/{fname}')\n",
    "                count_2 +=1\n",
    "            #im = Image.open(fpath)\n",
    "    \n",
    "print(count_1 + count_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb00c9-d02d-482e-b8af-3b79b264419f",
   "metadata": {},
   "source": [
    "## Número total de radiografias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01555e6-2cb4-46ba-9f0b-cad704faa001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of radiographs: 16824\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(1,30+1):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        content = f.read()\n",
    "        colist = content.split('\\n')\n",
    "        for i in colist:\n",
    "            if i:\n",
    "                count +=1\n",
    "print('Number of radiographs:',count)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ddfcb-0513-4213-8d70-59cd5b2e3e0b",
   "metadata": {},
   "source": [
    "## Número de radiografias para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "279fdd1e-4bca-4d4d-9822-8a444111c4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of radiographs: 11212\n"
     ]
    }
   ],
   "source": [
    "# train_folds: int = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "# val_folds: int = [21,22,23,24,25]\n",
    "\n",
    "count = 0\n",
    "for i in range(1,20+1):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        content = f.read()\n",
    "        colist = content.split('\\n')\n",
    "        for i in colist:\n",
    "            if i:\n",
    "                count +=1\n",
    "print('Number of radiographs:',count)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eca420d-ae53-4a14-890b-89c764f0185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "for i in range(21,25+1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462f03f-6ae1-4109-8d90-9e16a5e3fc06",
   "metadata": {},
   "source": [
    "## Número de radiografias para a validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39072e76-47d7-4c10-8fb9-895b5bad5516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of radiographs: 2808\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(21,25+1):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        content = f.read()\n",
    "        colist = content.split('\\n')\n",
    "        for i in colist:\n",
    "            if i:\n",
    "                count +=1\n",
    "print('Number of radiographs:',count)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e04513-a7cc-4bbe-a8d1-1596849a2ec0",
   "metadata": {},
   "source": [
    "## Número de radiografias para o teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d68bcef-d7b4-4f94-8fb8-a1848d3cc45e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of radiographs: 3357\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(25,30+1):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        content = f.read()\n",
    "        colist = content.split('\\n')\n",
    "        for i in colist:\n",
    "            if i:\n",
    "                count +=1\n",
    "print('Number of radiographs:',count)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621480c6-0b38-4cbe-b871-fe45e51a2df1",
   "metadata": {},
   "source": [
    "## Nº de homens e mulheres durante o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4be93293-25c6-4495-a084-c0bf425ea9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males in train: 4200\n",
      "Females in train: 7012\n"
     ]
    }
   ],
   "source": [
    "# train folds : fold 1 {1,2,3,4,5} ; fold 2 {6,7,8,9,10} ; fold 3 {11,12,13,14,15} ; fold 4 {16,17,18,19,20}\n",
    "# val folds : fold 1 {21,22,23,24,25}\n",
    "\n",
    "count_m = 0\n",
    "count_f = 0\n",
    "for i in range(1,20+1):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            img_relpath = line.strip()\n",
    "            filename = img_relpath.split('/')[-1]\n",
    "            sex = filename.split('-')[10]\n",
    "            if sex == 'M':\n",
    "                count_m +=1\n",
    "            else:\n",
    "                count_f +=1\n",
    "\n",
    "print('Males in train:',count_m)\n",
    "print('Females in train:',count_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce175d79-addd-469b-a660-c8eb51a155fc",
   "metadata": {},
   "source": [
    "## Nº de homens e mulheres durante a validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04fb21dd-f151-44a2-a671-00cc8cac973b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males in val: 1073\n",
      "Females in val: 1735\n"
     ]
    }
   ],
   "source": [
    "# train folds : fold 1 {1,2,3,4,5} ; fold 2 {6,7,8,9,10} ; fold 3 {11,12,13,14,15} ; fold 4 {16,17,18,19,20}\n",
    "# val folds : fold 1 {21,22,23,24,25}\n",
    "\n",
    "count_m = 0\n",
    "count_f = 0\n",
    "for i in range(21,25+1):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            img_relpath = line.strip()\n",
    "            filename = img_relpath.split('/')[-1]\n",
    "            sex = filename.split('-')[10]\n",
    "            if sex == 'M':\n",
    "                count_m +=1\n",
    "            else:\n",
    "                count_f +=1\n",
    "\n",
    "print('Males in val:',count_m)\n",
    "print('Females in val:',count_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e0411-7c9e-4b1c-b60c-4998c7ff3626",
   "metadata": {},
   "source": [
    "## Nº de pessoas por intervalo de idade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d63c580c-0083-4db3-8aab-f945f22fca07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de radiografias com idade: 8013\n",
      "Nº de pessoas entre [0,10] anos: 730\n",
      "Nº de pessoas entre [11,20] anos: 1414\n",
      "Nº de pessoas entre [21,30] anos: 2006\n",
      "Nº de pessoas entre [31,40] anos: 1435\n",
      "Nº de pessoas entre [41,50] anos: 1090\n",
      "Nº de pessoas entre [51,60] anos: 765\n",
      "Nº de pessoas entre [61,70] anos: 385\n",
      "Nº de pessoas entre [71,80] anos: 139\n",
      "Nº de pessoas entre [81,90] anos: 49\n",
      "Nº de pessoas entre [91,100] anos: 0\n",
      "Pessoas de fora: 0\n"
     ]
    }
   ],
   "source": [
    "# intervalos de idade: [0-10] ; [11-20] ; [21-30] ; [31-40] ; [41-50] ; [51-60] ; [61-70] ; [71-80] ; [81-90] ; [91-100]\n",
    "count = 0\n",
    "count_1 = 0 \n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "count_4 = 0\n",
    "count_5 = 0\n",
    "count_6 = 0\n",
    "count_7 = 0\n",
    "count_8 = 0\n",
    "count_9 = 0\n",
    "count_10 = 0\n",
    "\n",
    "count_ = 0\n",
    "\n",
    "for i in range(1,30+1):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            img_relpath = line.strip()\n",
    "            filename = img_relpath.split('/')[-1]\n",
    "            age = filename.split('-')[12][1:]\n",
    "            \n",
    "            if age == 'NA':\n",
    "                continue\n",
    "            else:\n",
    "                age = int(filename.split('-')[12][1:])\n",
    "                #print(age)\n",
    "                count += 1\n",
    "                \n",
    "            if age <= 10:\n",
    "                count_1 += 1\n",
    "            elif 10< age <= 20:\n",
    "                count_2 += 1\n",
    "            elif 20< age <=30 :\n",
    "                count_3 += 1\n",
    "            elif 30< age <=40:\n",
    "                count_4 += 1\n",
    "            elif 40< age <=50:\n",
    "                count_5 += 1\n",
    "            elif 50< age <=60:\n",
    "                count_6 += 1\n",
    "            elif 60< age <=70:\n",
    "                count_7 += 1\n",
    "            elif 70< age <=80:\n",
    "                count_8 += 1\n",
    "            elif 80< age <=90:\n",
    "                count_9 += 1\n",
    "            elif 90< age <=100:\n",
    "                count_10 += 1 \n",
    "            else:\n",
    "                count_ += 1\n",
    "            \n",
    "        #contagem = {'Males':count_males,'Females':count_females}\n",
    "\n",
    "print('Nº de radiografias com idade:',count)\n",
    "print('Nº de pessoas entre [0,10] anos:',count_1)\n",
    "print('Nº de pessoas entre [11,20] anos:',count_2)\n",
    "print('Nº de pessoas entre [21,30] anos:', count_3)\n",
    "print('Nº de pessoas entre [31,40] anos:', count_4)\n",
    "print('Nº de pessoas entre [41,50] anos:', count_5)\n",
    "print('Nº de pessoas entre [51,60] anos:', count_6)\n",
    "print('Nº de pessoas entre [61,70] anos:', count_7)\n",
    "print('Nº de pessoas entre [71,80] anos:', count_8)\n",
    "print('Nº de pessoas entre [81,90] anos:', count_9)\n",
    "print('Nº de pessoas entre [91,100] anos:', count_10)\n",
    "print('Pessoas de fora:',count_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070efe9-aea7-4271-88bc-54e2f9efc8eb",
   "metadata": {},
   "source": [
    "## Nº de homens e mulheres por intervalo de idade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc1127aa-602e-4a50-a442-68cf9e28564a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de radiografias com idade: 8013\n",
      "Nº de mulheres entre [0,10] anos: 378\n",
      "Nº de mulheres entre [11,20] anos: 843\n",
      "Nº de mulheres entre [21,30] anos: 1267\n",
      "Nº de mulheres entre [31,40] anos: 893\n",
      "Nº de mulheres entre [41,50] anos: 692\n",
      "Nº de mulheres entre [51,60] anos: 502\n",
      "Nº de mulheres entre [61,70] anos: 233\n",
      "Nº de mulheres entre [71,80] anos: 81\n",
      "Nº de mulheres entre [81,90] anos: 31\n",
      "Nº de mulheres entre [91,100] anos: 0\n",
      "Mulheres de fora: 0\n",
      "\n",
      "Nº de radiografias com idade: 8013\n",
      "Nº de homens entre [0,10] anos: 352\n",
      "Nº de homens entre [11,20] anos: 571\n",
      "Nº de homens entre [21,30] anos: 739\n",
      "Nº de homens entre [31,40] anos: 542\n",
      "Nº de homens entre [41,50] anos: 398\n",
      "Nº de homens entre [51,60] anos: 263\n",
      "Nº de homens entre [61,70] anos: 152\n",
      "Nº de homens entre [71,80] anos: 58\n",
      "Nº de homens entre [81,90] anos: 18\n",
      "Nº de homens entre [91,100] anos: 0\n",
      "Homens de fora: 0\n"
     ]
    }
   ],
   "source": [
    "# intervalos de idade: [0-10] ; [11-20] ; [21-30] ; [31-40] ; [41-50] ; [51-60] ; [61-70] ; [71-80] ; [81-90] ; [91-100]\n",
    "count = 0\n",
    "count_1 = 0 \n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "count_4 = 0\n",
    "count_5 = 0\n",
    "count_6 = 0\n",
    "count_7 = 0\n",
    "count_8 = 0\n",
    "count_9 = 0\n",
    "count_10 = 0\n",
    "\n",
    "count_ = 0\n",
    "\n",
    "count_11 = 0 \n",
    "count_21 = 0\n",
    "count_31 = 0\n",
    "count_41 = 0\n",
    "count_51 = 0\n",
    "count_61 = 0\n",
    "count_71 = 0\n",
    "count_81 = 0\n",
    "count_91 = 0\n",
    "count_101 = 0\n",
    "\n",
    "count__ = 0\n",
    "\n",
    "for i in range(1,30+1):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            img_relpath = line.strip()\n",
    "            filename = img_relpath.split('/')[-1]\n",
    "            age = filename.split('-')[12][1:]\n",
    "            if age == 'NA':\n",
    "                continue\n",
    "            else:\n",
    "                age = int(filename.split('-')[12][1:])\n",
    "                count += 1\n",
    "            sex = filename.split('-')[10]\n",
    "            if sex == 'M':\n",
    "                if age <= 10:\n",
    "                    count_11 += 1\n",
    "                elif 10< age <= 20:\n",
    "                    count_21 += 1\n",
    "                elif 20< age <=30 :\n",
    "                    count_31 += 1\n",
    "                elif 30< age <=40:\n",
    "                    count_41 += 1\n",
    "                elif 40< age <=50:\n",
    "                    count_51 += 1\n",
    "                elif 50< age <=60:\n",
    "                    count_61 += 1\n",
    "                elif 60< age <=70:\n",
    "                    count_71 += 1\n",
    "                elif 70< age <=80:\n",
    "                    count_81 += 1\n",
    "                elif 80< age <=90:\n",
    "                    count_91 += 1\n",
    "                elif 90< age <=100:\n",
    "                    count_101 += 1 \n",
    "                else:\n",
    "                    count__ += 1\n",
    "                    \n",
    "                \n",
    "            else:\n",
    "                if age <= 10:\n",
    "                    count_1 += 1\n",
    "                elif 10< age <= 20:\n",
    "                    count_2 += 1\n",
    "                elif 20< age <=30 :\n",
    "                    count_3 += 1\n",
    "                elif 30< age <=40:\n",
    "                    count_4 += 1\n",
    "                elif 40< age <=50:\n",
    "                    count_5 += 1\n",
    "                elif 50< age <=60:\n",
    "                    count_6 += 1\n",
    "                elif 60< age <=70:\n",
    "                    count_7 += 1\n",
    "                elif 70< age <=80:\n",
    "                    count_8 += 1\n",
    "                elif 80< age <=90:\n",
    "                    count_9 += 1\n",
    "                elif 90< age <=100:\n",
    "                    count_10 += 1 \n",
    "                else:\n",
    "                    count_ += 1 \n",
    "            \n",
    "        #contagem = {'Males':count_males,'Females':count_females}\n",
    "\n",
    "print('Nº de radiografias com idade:',count)\n",
    "print('Nº de mulheres entre [0,10] anos:',count_1)\n",
    "print('Nº de mulheres entre [11,20] anos:',count_2)\n",
    "print('Nº de mulheres entre [21,30] anos:', count_3)\n",
    "print('Nº de mulheres entre [31,40] anos:', count_4)\n",
    "print('Nº de mulheres entre [41,50] anos:', count_5)\n",
    "print('Nº de mulheres entre [51,60] anos:', count_6)\n",
    "print('Nº de mulheres entre [61,70] anos:', count_7)\n",
    "print('Nº de mulheres entre [71,80] anos:', count_8)\n",
    "print('Nº de mulheres entre [81,90] anos:', count_9)\n",
    "print('Nº de mulheres entre [91,100] anos:', count_10)\n",
    "print('Mulheres de fora:',count_)\n",
    "print()\n",
    "print('Nº de radiografias com idade:',count)\n",
    "print('Nº de homens entre [0,10] anos:',count_11)\n",
    "print('Nº de homens entre [11,20] anos:',count_21)\n",
    "print('Nº de homens entre [21,30] anos:', count_31)\n",
    "print('Nº de homens entre [31,40] anos:', count_41)\n",
    "print('Nº de homens entre [41,50] anos:', count_51)\n",
    "print('Nº de homens entre [51,60] anos:', count_61)\n",
    "print('Nº de homens entre [61,70] anos:', count_71)\n",
    "print('Nº de homens entre [71,80] anos:', count_81)\n",
    "print('Nº de homens entre [81,90] anos:', count_91)\n",
    "print('Nº de homens entre [91,100] anos:', count_101)\n",
    "print('Homens de fora:',count__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce9987b-8a9a-49ac-b667-4cbd9466e271",
   "metadata": {},
   "source": [
    "## Contagem de acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58625eba-578a-4a34-a521-fba31db3cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(ground_truth= list, prediction= list):\n",
    "    acertos_homens, acertos_mulheres = 0, 0\n",
    "    total_homens, total_mulheres = 0, 0\n",
    "    \n",
    "    for idx, (img, label) in tqdm(enumerate(val_dataloader)):\n",
    "        img, label = img.cuda(), label.cuda()\n",
    "        preds = model(img)\n",
    "        prediction = torch.argmax(preds).item()\n",
    "        ground_truth = label.item()\n",
    "        \n",
    "        if ground_truth == 0:\n",
    "            total_mulheres += 1\n",
    "        else:\n",
    "            total_homens += 1\n",
    "\n",
    "        if ground_truth == prediction:\n",
    "            if ground_truth == 0:\n",
    "                acertos_mulheres += 1\n",
    "            else:\n",
    "                acertos_homens += 1\n",
    "\n",
    "    print(f'Mulheres: {total_mulheres}')\n",
    "    print(f'Homens: {total_homens}')\n",
    "    print(f'Total: {total_mulheres + total_homens}')\n",
    "    print(f'Acertos Mulheres: {acertos_mulheres}')\n",
    "    print(f'Acertos Homens: {acertos_homens}')\n",
    "\n",
    "    return acertos_mulheres, acertos_homens\n",
    "\n",
    "get_count(ground_truth, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f0c8c-edf2-4150-be04-8b3a206d7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precison\n",
    "def precision(outputs, labels):\n",
    "    op = outputs.to(device)\n",
    "    la = labels.to(device)\n",
    "    _, preds = torch.max(op, dim=1)\n",
    "    return torch.tensor(precision_score(la,preds, average=‘weighted’))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ae4ca59-7518-4617-bf8d-c1ab263cc587",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting captum\n",
      "  Downloading captum-0.5.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 992 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.8/site-packages (from captum) (1.12.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from captum) (3.5.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from captum) (1.21.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.6->captum) (3.10.0.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->captum) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->captum) (3.0.8)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->captum) (4.32.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->captum) (9.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->captum) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->captum) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->captum) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
      "Installing collected packages: captum\n",
      "Successfully installed captum-0.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cde7148-1b87-41ae-8fd7-939c838c85ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99133522-76a7-4795-b668-c6cae7ce1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "transform = T.Compose([\n",
    "                T.Resize((inputs.img_size, inputs.img_size)),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(inputs.MEAN, inputs.STDV)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d8c37d0-6937-4ab1-a85f-441b47241834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only horizontal flip augmentation.\n",
      "Using only horizontal flip augmentation.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val_dataset = FullRadiographSexDataset(root_dir=inputs.DATASET_DIR,fold_nums=inputs.val_folds,transforms=get_transforms(inputs, subset=subset))\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=1,shuffle=False,num_workers=0)\n",
    "\n",
    "train_dataset = FullRadiographSexDataset(root_dir=inputs.DATASET_DIR,fold_nums=inputs.train_folds,transforms=get_transforms(inputs, subset=subset))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=1,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a23f164e-a7d3-402f-abe1-ecbc55cef163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the classes\n",
    "for i in range(1,31):\n",
    "    filepath = f'/home/bernardo/datasets/pan-radiographs/splits/{i:02d}.txt'\n",
    "    with open(filepath) as f:\n",
    "        for line in f: #ler cada linha do txt\n",
    "            fname = line.strip().split('/')[2] #retirar o \\n\n",
    "            sex = fname.split('-')[10]\n",
    "            #print(sex)\n",
    "            if fname.split('-')[0] == 'pan': #separar os arquivos pan e panreport\n",
    "                fpath = os.path.join(f'/home/bernardo/datasets/pan-radiographs/1st-set/images/{fname}')\n",
    "            else:\n",
    "                fpath = os.path.join(f'/home/bernardo/datasets/pan-radiographs/2nd-set/images/{fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed68f11f-d553-4342-ad61-341aaeddf1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_image_features(algorithm, input, **kwargs):\n",
    "    net.zero_grad()\n",
    "    tensor_attributions = algorithm.attribute(input,\n",
    "                                              target=labels[ind],\n",
    "                                              **kwargs\n",
    "                                             )\n",
    "    \n",
    "    return tensor_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0b489438-7f40-4e7b-b406-659d78f6b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(val_dataloader)\n",
    "images, labels = dataiter.next()\n",
    "ind = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "84cbd2cf-d169-4a17-bb27-24a3353b4072",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1079/1346976814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msaliency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaliency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaliency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "inputs = Inputs(selected_model='efficientnet-b0')\n",
    "model = get_classification_model(inputs.model_name, 2)\n",
    "checkpoint = torch.load('/home/bernardo/github/sex-age-estimation/backup-bia/patch-1/checkpoint-efficientnet-b0-fold-2-max-acc.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "saliency = Saliency(model)\n",
    "grads = saliency.attribute(images, target=labels[ind].item())\n",
    "    \n",
    "grads = np.transpose(grads.squeeze().cpu().detach().numpy(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4e9c24b8-0e9f-4105-bb1d-0f1dd767777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import torch    \n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import torchvision.transforms as transforms\n",
    "from pytorch_grad_cam import EigenCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, scale_cam_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d015b3e7-8222-4280-b56b-7ea43b656e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = np.random.uniform(0, 255, size=(80, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7121fc3f-ad6e-4b60-bafd-aebb29bd252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_detections(results):\n",
    "    detections = results.pandas().xyxy[0]\n",
    "    detections = detections.to_dict()\n",
    "    boxes, colors, names = [], [], []\n",
    "\n",
    "    for i in range(len(detections[\"xmin\"])):\n",
    "        confidence = detections[\"confidence\"][i]\n",
    "        if confidence < 0.2:\n",
    "            continue\n",
    "        xmin = int(detections[\"xmin\"][i])\n",
    "        ymin = int(detections[\"ymin\"][i])\n",
    "        xmax = int(detections[\"xmax\"][i])\n",
    "        ymax = int(detections[\"ymax\"][i])\n",
    "        name = detections[\"name\"][i]\n",
    "        category = int(detections[\"class\"][i])\n",
    "        color = COLORS[category]\n",
    "\n",
    "        boxes.append((xmin, ymin, xmax, ymax))\n",
    "        colors.append(color)\n",
    "        names.append(name)\n",
    "    return boxes, colors, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d0040e5f-e77c-4fdb-9bd4-679550d3d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_detections(boxes, colors, names, img):\n",
    "    for box, color, name in zip(boxes, colors, names):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (xmin, ymin),\n",
    "            (xmax, ymax),\n",
    "            color, \n",
    "            2)\n",
    "\n",
    "        cv2.putText(img, name, (xmin, ymin - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2,\n",
    "                    lineType=cv2.LINE_AA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5943ec7-ac5f-434f-a68b-a526736eab75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
